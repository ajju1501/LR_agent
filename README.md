# LoginRadius Documentation Chatbot

A RAG-based conversational chatbot for LoginRadius documentation, powered by HuggingFace Inference API.

## Features

- ðŸ’¬ **AI Chat** â€” Ask questions about LoginRadius docs, get answers with code examples
- ðŸ“š **RAG Pipeline** â€” Retrieval-Augmented Generation with source citations
- ðŸ”— **Source References** â€” Every answer links back to documentation sources
- ðŸ§  **HuggingFace LLM** â€” Cloud-based inference via HuggingFace router API
- ðŸ•·ï¸ **Doc Scraper** â€” Automatically scrapes and indexes LoginRadius documentation
- ðŸ’¾ **Session Persistence** â€” Chat history saved in PostgreSQL

## Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | Next.js, React, TailwindCSS |
| **Backend** | Node.js, Express, TypeScript |
| **LLM** | HuggingFace Inference API (Qwen/Qwen3-Coder-Next) |
| **Embeddings** | sentence-transformers/all-MiniLM-L6-v2 |
| **Vector DB** | ChromaDB |
| **Database** | PostgreSQL |

## Prerequisites

- Node.js 18+
- Docker & Docker Compose (for PostgreSQL & ChromaDB)
- HuggingFace API token ([get one here](https://huggingface.co/settings/tokens))

## Quick Start

### 1. Clone & configure

```bash
cd backend
cp .env.example .env
```

Edit `.env` and set your HuggingFace token:
```
HF_TOKEN=hf_your_token_here
```

> **Important:** Your token needs the "Make calls to Inference Providers" permission. Create a **fine-grained** token at [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).

### 2. Start infrastructure

```bash
docker compose up -d   # PostgreSQL + ChromaDB
```

### 3. Start backend

```bash
cd backend
npm install
npm run dev
```

### 4. Start frontend

```bash
cd frontend
npm install
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## Project Structure

```
LR_agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ env.ts              # Environment config
â”‚   â”‚   â”‚   â”œâ”€â”€ huggingface.ts      # HuggingFace API client
â”‚   â”‚   â”‚   â””â”€â”€ database.ts         # ChromaDB manager
â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â”œâ”€â”€ chatController.ts   # Chat API handlers
â”‚   â”‚   â”‚   â””â”€â”€ documentController.ts
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ chatRoutes.ts       # /api/chat/*
â”‚   â”‚   â”‚   â””â”€â”€ documentRoutes.ts   # /api/documents/*
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ llmService.ts       # LLM response generation
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddingService.ts # Text embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ ragPipelineService.ts # RAG orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ retrievalService.ts # Vector search
â”‚   â”‚   â”‚   â”œâ”€â”€ scraperService.ts   # Doc scraper
â”‚   â”‚   â”‚   â”œâ”€â”€ documentService.ts  # Document processing
â”‚   â”‚   â”‚   â””â”€â”€ sessionService.ts   # Chat sessions (PostgreSQL)
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts            # TypeScript interfaces
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ promptBuilder.ts    # RAG prompt construction
â”‚   â”‚   â”‚   â”œâ”€â”€ chunkDocument.ts    # Text chunking
â”‚   â”‚   â”‚   â””â”€â”€ logger.ts           # Winston logger
â”‚   â”‚   â”œâ”€â”€ app.ts                  # Express app setup
â”‚   â”‚   â””â”€â”€ server.ts               # Server entry point
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                    # Next.js pages
â”‚   â”‚   â”œâ”€â”€ components/             # React components
â”‚   â”‚   â”œâ”€â”€ context/ChatContext.tsx  # Chat state management
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts              # Backend API client
â”‚   â”‚   â”‚   â””â”€â”€ types.ts            # Frontend types
â”‚   â”‚   â””â”€â”€ styles/globals.css
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ init.sql
```

## Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `HF_TOKEN` | HuggingFace API token | *(required)* |
| `HF_MODEL` | Chat model | `Qwen/Qwen3-Coder-Next:novita` |
| `HF_EMBEDDING_MODEL` | Embedding model | `sentence-transformers/all-MiniLM-L6-v2` |
| `HF_BASE_URL` | HuggingFace API base | `https://router.huggingface.co/v1` |
| `DATABASE_URL` | PostgreSQL connection | `postgresql://chatbot_user:chatbot_pass@localhost:5432/lr_chatbot` |
| `PORT` | Backend port | `5000` |
| `FRONTEND_URL` | Frontend URL (CORS) | `http://localhost:3000` |

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/chat/new` | Create a new chat session |
| POST | `/api/chat/send` | Send a message |
| GET | `/api/chat/sessions` | List user sessions |
| GET | `/api/chat/history/:id` | Get chat history |
| DELETE | `/api/chat/:id` | Delete a session |
| POST | `/api/documents/ingest` | Ingest a document |
| POST | `/api/documents/scrape-loginradius` | Scrape LR docs |
| GET | `/api/documents` | List documents |
| GET | `/api/health` | Health check |

## Troubleshooting

### HuggingFace 403 error
Your token doesn't have "Inference Providers" permission. Create a new **fine-grained** token at [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) with that permission enabled.

### HuggingFace 429 rate limit
The client has built-in retry with exponential backoff. If persistent, wait a few minutes or consider a paid HuggingFace plan.

### Database connection errors
Make sure Docker is running: `docker compose up -d`

## License

MIT
